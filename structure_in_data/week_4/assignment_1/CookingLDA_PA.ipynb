{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment\n",
    "## Готовим LDA по рецептам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как вы уже знаете, в тематическом моделировании делается предположение о том, что для определения тематики порядок слов в документе не важен; об этом гласит гипотеза <<мешка слов>>. Сегодня мы будем работать с несколько нестандартной для тематического моделирования коллекцией, которую можно назвать <<мешком ингредиентов>>, потому что на состоит из рецептов блюд разных кухонь. Тематические модели ищут слова, которые часто вместе встречаются в документах, и составляют из них темы. Мы попробуем применить эту идею к рецептам и найти кулинарные <<темы>>. Эта коллекция хороша тем, что не требует предобработки. Кроме того, эта задача достаточно наглядно иллюстрирует принцип работы тематических моделей.\n",
    "\n",
    "Для выполнения заданий, помимо часто используемых в курсе библиотек, потребуются модули json и gensim. Первый входит в дистрибутив Anaconda, второй можно поставить командой \n",
    "\n",
    "pip install gensim\n",
    "\n",
    "или\n",
    "\n",
    "conda install gensim\n",
    "\n",
    "Построение модели занимает некоторое время. На ноутбуке с процессором Intel Core i7 и тактовой частотой 2400 МГц на построение одной модели уходит менее 10 минут."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Коллекция дана в json-формате: для каждого рецепта известны его id, кухня (\"cuisine\") и список ингредиентов, в него входящих. Загрузить данные можно с помощью модуля json (он входит в дистрибутив Anaconda):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"recipes.json\") as f:\n",
    "    recipes = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'cuisine': u'greek', u'id': 10259, u'ingredients': [u'romaine lettuce', u'black olives', u'grape tomatoes', u'garlic', u'pepper', u'purple onion', u'seasoning', u'garbanzo beans', u'feta cheese crumbles']}\n"
     ]
    }
   ],
   "source": [
    "print recipes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Составление корпуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша коллекция небольшая и влезает в оперативную память. Gensim может работать с такими данными и не требует их сохранения на диск в специальном формате. Для этого коллекция должна быть представлена в виде списка списков, каждый внутренний список соответствует отдельному документу и состоит из его слов. Пример коллекции из двух документов: \n",
    "\n",
    "[[\"hello\", \"world\"], [\"programming\", \"in\", \"python\"]]\n",
    "\n",
    "Преобразуем наши данные в такой формат, а затем создадим объекты corpus и dictionary, с которыми будет работать модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = [recipe[\"ingredients\"] for recipe in recipes]\n",
    "dictionary = corpora.Dictionary(texts)   # составляем словарь\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]  # составляем корпус документов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'romaine lettuce', u'black olives', u'grape tomatoes', u'garlic', u'pepper', u'purple onion', u'seasoning', u'garbanzo beans', u'feta cheese crumbles']\n",
      "[(9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1)]\n"
     ]
    }
   ],
   "source": [
    "print texts[0]\n",
    "print corpus[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У объекта dictionary есть две полезных переменных: dictionary.id2token и dictionary.token2id; эти словари позволяют находить соответствие между ингредиентами и их индексами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели\n",
    "Вам может понадобиться [документация](https://radimrehurek.com/gensim/models/ldamodel.html) LDA в gensim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 1.__ Обучите модель LDA с 40 темами, установив количество проходов по коллекции 5 и оставив остальные параметры по умолчанию. Затем вызовите метод модели show_topics, указав количество тем 40 и количество токенов 10, и сохраните результат (топы ингредиентов в темах) в отдельную переменную. Если при вызове метода show_topics указать параметр formatted=True, то топы ингредиентов будет удобно выводить на печать, если formatted=False, будет удобно работать со списком программно. Выведите топы на печать, рассмотрите темы, а затем ответьте на вопрос:\n",
    "\n",
    "Сколько раз ингредиенты \"salt\", \"sugar\", \"water\", \"mushrooms\", \"chicken\", \"eggs\" встретились среди топов-10 всех 40 тем? При ответе __не нужно__ учитывать составные ингредиенты, например, \"hot water\".\n",
    "\n",
    "Передайте 6 чисел в функцию save_answers1 и загрузите сгенерированный файл в форму.\n",
    "\n",
    "У gensim нет возможности фиксировать случайное приближение через параметры метода, но библиотека использует numpy для инициализации матриц. Поэтому, по утверждению автора библиотеки, фиксировать случайное приближение нужно командой, которая написана в следующей ячейке. __Перед строкой кода с построением модели обязательно вставляйте указанную строку фиксации random.seed.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel\n",
    "np.random.seed(76543)\n",
    "# здесь код для построения модели:\n",
    "lda = LdaModel(corpus, num_topics=40, passes = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topics = lda.show_topics(formatted=False, num_topics = 40,  num_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for token in [\"salt\", \"sugar\", \"water\", \"mushrooms\", \"chicken\", \"eggs\"]:\n",
    "    token_id = str(dictionary.token2id[token])\n",
    "    \n",
    "    n = 0\n",
    "    for topic in topics:\n",
    "        for item in topic[1]:\n",
    "            if token_id == item[0]:\n",
    "                n += 1\n",
    "    results.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20, 7, 8, 1, 1, 1]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_answers1(c_salt, c_sugar, c_water, c_mushrooms, c_chicken, c_eggs):\n",
    "    with open(\"cooking_LDA_pa_task1.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([str(el) for el in [c_salt, c_sugar, c_water, c_mushrooms, c_chicken, c_eggs]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_answers1(results[0], results[1], results[2], results[3], results[4], results[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Фильтрация словаря\n",
    "В топах тем гораздо чаще встречаются первые три рассмотренных ингредиента, чем последние три. При этом наличие в рецепте курицы, яиц и грибов яснее дает понять, что мы будем готовить, чем наличие соли, сахара и воды. Таким образом, даже в рецептах есть слова, часто встречающиеся в текстах и не несущие смысловой нагрузки, и поэтому их не желательно видеть в темах. Наиболее простой прием борьбы с такими фоновыми элементами - фильтрация словаря по частоте. Обычно словарь фильтруют с двух сторон: убирают очень редкие слова (в целях экономии памяти) и очень частые слова (в целях повышения интерпретируемости тем). Мы уберем только частые слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "dictionary2 = copy.deepcopy(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 2.__ У объекта dictionary2 есть переменная dfs - это словарь, ключами которого являются id токена, а элементами - число раз, сколько слово встретилось во всей коллекции. Сохраните в отдельный список ингредиенты, которые встретились в коллекции больше 4000 раз. Вызовите метод словаря filter_tokens, подав в качестве первого аргумента полученный список популярных ингредиентов. Вычислите две величины: dict_size_before и dict_size_after - размер словаря до и после фильтрации.\n",
    "\n",
    "Затем, используя новый словарь, создайте новый корпус документов, corpus2, по аналогии с тем, как это сделано в начале ноутбука. Вычислите две величины: corpus_size_before и corpus_size_after - суммарное количество ингредиентов в корпусе (иными словами, сумма длин всех документов коллекции) до и после фильтрации.\n",
    "\n",
    "Передайте величины dict_size_before, dict_size_after, corpus_size_before, corpus_size_after в функцию save_answers2 и загрузите сгенерированный файл в форму."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "popular_ingredients = []\n",
    "for token in dictionary2.dfs: \n",
    "    if dictionary2.dfs[token] > 4000:\n",
    "        popular_ingredients.append(token)\n",
    "        \n",
    "dictionary2.filter_tokens(popular_ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6714, 6702)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_size_before = len(dictionary.dfs)\n",
    "dict_size_after = len(dictionary2.dfs)\n",
    "\n",
    "dict_size_before, dict_size_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus2 = [dictionary2.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_corpus_size(corpus):\n",
    "    size = 0\n",
    "    for item in corpus:\n",
    "        size += len(item)\n",
    "    return size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus_size_before = get_corpus_size(corpus)\n",
    "corpus_size_after = get_corpus_size(corpus2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_answers2(dict_size_before, dict_size_after, corpus_size_before, corpus_size_after):\n",
    "    with open(\"cooking_LDA_pa_task2.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([str(el) for el in [dict_size_before, dict_size_after, corpus_size_before, corpus_size_after]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_answers2(dict_size_before, dict_size_after, corpus_size_before, corpus_size_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравнение когерентностей\n",
    "__Задание 3.__ Постройте еще одну модель по корпусу corpus2 и словарю dictioanary2, остальные параметры оставьте такими же, как при первом построении модели. Сохраните новую модель в другую переменную (не перезаписывайте предыдущую модель). Не забудьте про фиксирование seed!\n",
    "\n",
    "Затем воспользуйтесь методом top_topics модели, чтобы вычислить ее когерентность. Передайте в качестве аргумента соответствующий модели корпус. Метод вернет список кортежей (топ токенов, когерентность), отсортированных по убыванию последней. Вычислите среднюю по всем темам когерентность для каждой из двух моделей и передайте в функцию save_answers3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(76543)\n",
    "# здесь код для построения модели:\n",
    "lda2 = LdaModel(corpus2, num_topics=40, passes = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_topics = lda.top_topics(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_topics2 = lda2.top_topics(corpus2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_coherence(topics):\n",
    "    coherences = []\n",
    "    for item in topics:\n",
    "        coherences.extend(map(lambda x: x[0], item[0]))\n",
    "    return np.mean(coherences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.033168301129107555, 0.033831763128515796)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence = get_coherence(top_topics)\n",
    "coherence2 = get_coherence(top_topics2)\n",
    "\n",
    "coherence, coherence2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_answers3(coherence, coherence2):\n",
    "    with open(\"cooking_LDA_pa_task3.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([\"%3f\"%el for el in [coherence, coherence2]]))\n",
    "        \n",
    "save_answers3(coherence, coherence2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считается, что когерентность хорошо соотносится с человеческими оценками интерпретируемости тем. Поэтому на больших текстовых коллекциях когерентность обычно повышается, если убрать фоновую лексику. Однако в нашем случае этого не произошло. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Изучение влияния гиперпараметра alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом разделе мы будем работать со второй моделью, то есть той, которая построена по сокращенному корпусу. \n",
    "\n",
    "Пока что мы посмотрели только на матрицу темы-слова, теперь давайте посмотрим на матрицу темы-документы. Выведите темы для нулевого (или любого другого) документа из корпуса, воспользовавшись методом get_document_topics второй модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.1024999999999999),\n",
       " (8, 0.10249999999999994),\n",
       " (11, 0.10249999999999994),\n",
       " (13, 0.10249999999999994),\n",
       " (19, 0.10249999999999994),\n",
       " (21, 0.10249999999999994),\n",
       " (31, 0.10249999999999991),\n",
       " (33, 0.10249999999999994),\n",
       " (37, 0.10249999999999994)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda2.get_document_topics(corpus[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также выведите содержимое переменной .alpha второй модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.025,  0.025,  0.025,  0.025,  0.025,  0.025,  0.025,  0.025,\n",
       "        0.025,  0.025,  0.025,  0.025,  0.025,  0.025,  0.025,  0.025,\n",
       "        0.025,  0.025,  0.025,  0.025,  0.025,  0.025,  0.025,  0.025,\n",
       "        0.025,  0.025,  0.025,  0.025,  0.025,  0.025,  0.025,  0.025,\n",
       "        0.025,  0.025,  0.025,  0.025,  0.025,  0.025,  0.025,  0.025])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda2.alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У вас должно получиться, что документ характеризуется небольшим числом тем. Попробуем поменять гиперпараметр alpha, задающий априорное распределение Дирихле для распределений тем в документах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 4.__ Обучите третью модель: используйте сокращенный корпус (corpus2 и dictionary2) и установите параметр __alpha=1__, passes=5. Не забудьте задать количество тем и зафиксировать seed! Выведите темы новой модели для нулевого документа; должно получиться, что распределение над множеством тем практически равномерное. Чтобы убедиться в том, что во второй модели документы описываются гораздо более разреженными распределениями, чем в третьей, посчитайте суммарное количество элементов, __превосходящих 0.01__, в матрицах темы-документы обеих моделей. Другими словами, запросите темы  модели для каждого документа с параметром minimum_probability=0.01 и просуммируйте число элементов в получаемых массивах. Передайте две суммы (сначала для модели с alpha по умолчанию, затем для модели в alpha=1) в функцию save_answers4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(76543)\n",
    "# здесь код для построения модели:\n",
    "lda3 = LdaModel(corpus2, num_topics=40, passes = 5, alpha = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lda3.get_document_topics(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(198957, 1590960)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_count_model(lda, corpus):\n",
    "    count = 0\n",
    "    for doc in corpus:\n",
    "        topics = lda.get_document_topics(doc, minimum_probability=0.01)\n",
    "        count += len(topics)\n",
    "    return count\n",
    "\n",
    "count_model2 = get_count_model(lda2, corpus2)\n",
    "count_model3 = get_count_model(lda3, corpus2)\n",
    "\n",
    "count_model2, count_model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_answers4(count_model2, count_model3):\n",
    "    with open(\"cooking_LDA_pa_task4.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([str(el) for el in [count_model2, count_model3]]))\n",
    "        \n",
    "save_answers4(count_model2, count_model3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, гиперпараметр alpha влияет на разреженность распределений тем в документах. Аналогично гиперпараметр eta влияет на разреженность распределений слов в темах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA как способ понижения размерности\n",
    "Иногда распределения над темами, найденные с помощью LDA, добавляют в матрицу объекты-признаки как дополнительные, семантические, признаки, и это может улучшить качество решения задачи. Для простоты давайте просто обучим классификатор рецептов на кухни на признаках, полученных из LDA, и измерим точность (accuracy).\n",
    "\n",
    "__Задание 5.__ Используйте модель, построенную по сокращенной выборке с alpha по умолчанию (вторую модель). Составьте матрицу $\\Theta = p(t|d)$ вероятностей тем в документах; вы можете использовать тот же метод get_document_topics, а также вектор правильных ответов y (в том же порядке, в котором рецепты идут в переменной recipes). Создайте объект RandomForestClassifier со 100 деревьями, с помощью функции cross_val_score вычислите среднюю accuracy по трем фолдам (перемешивать данные не нужно) и передайте в функцию save_answers5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "num_doc = 0\n",
    "for doc in corpus2:\n",
    "    results[num_doc] = {}\n",
    "    topics = lda2.get_document_topics(doc)\n",
    "    for item in topics:\n",
    "        results[num_doc][item[0]] = item[1]\n",
    "    num_doc += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame.from_dict(results).fillna(0).T\n",
    "y = np.array([recipe['cuisine'] for recipe in recipes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39774, 40), (39774,))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "scores = cross_val_score(clf, X, y, cv=3, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_answers5(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_answers5(accuracy):\n",
    "     with open(\"cooking_LDA_pa_task5.txt\", \"w\") as fout:\n",
    "        fout.write(str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для такого большого количества классов это неплохая точность. Вы можете попроовать обучать RandomForest на исходной матрице частот слов, имеющей значительно большую размерность, и увидеть, что accuracy увеличивается на 10-15%. Таким образом, LDA собрал не всю, но достаточно большую часть информации из выборки, в матрице низкого ранга."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA --- вероятностная модель\n",
    "Матричное разложение, использующееся в LDA, интерпретируется как следующий процесс генерации документов.\n",
    "\n",
    "Для документа $d$ длины $n_d$:\n",
    "1. Из априорного распределения Дирихле с параметром alpha сгенерировать распределение над множеством тем: $\\theta_d \\sim Dirichlet(\\alpha)$\n",
    "1. Для каждого слова $w = 1, \\dots, n_d$:\n",
    "    1. Сгенерировать тему из дискретного распределения $t \\sim \\theta_{d}$\n",
    "    1. Сгенерировать слово из дискретного распределения $w \\sim \\phi_{t}$.\n",
    "    \n",
    "Подробнее об этом в [Википедии](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation).\n",
    "\n",
    "В контексте нашей задачи получается, что, используя данный генеративный процесс, можно создавать новые рецепты. Вы можете передать в функцию модель и число ингредиентов и сгенерировать рецепт :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_recipe(model, num_ingredients):\n",
    "    theta = np.random.dirichlet(model.alpha)\n",
    "    for i in range(num_ingredients):\n",
    "        t = np.random.choice(np.arange(model.num_topics), p=theta)\n",
    "        topic = model.show_topic(0, topn=model.num_terms)\n",
    "        topic_distr = [x[1] for x in topic]\n",
    "        terms = [x[0] for x in topic]\n",
    "        w = np.random.choice(terms, p=topic_distr)\n",
    "        print w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "522\n",
      "38\n",
      "100\n",
      "779\n",
      "828\n"
     ]
    }
   ],
   "source": [
    "generate_recipe(lda, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Интерпретация построенной модели\n",
    "Вы можете рассмотреть топы ингредиентов каждой темы. Большиснтво тем сами по себе похожи на рецепты; в некоторых собираются продукты одного вида, например, свежие фрукты или разные виды сыра.\n",
    "\n",
    "Попробуем эмпирически соотнести наши темы с национальными кухнями (cuisine). Построим матрицу A размера темы x кухни, ее элементы $a_{tc}$ - суммы p(t|d) по всем документам d, которые отнесены к кухне c. Нормируем матрицу на частоты рецептов по разным кухням, чтобы избежать дисбаланса между кухнями. Следующая функция получает на вход объект модели, объект корпуса и исходные данные и возвращает нормированную матрицу A. Ее удобно визуализировать с помощью seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import seaborn\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_topic_cuisine_matrix(model, corpus, recipes):\n",
    "    # составляем вектор целевых признаков\n",
    "    targets = list(set([recipe[\"cuisine\"] for recipe in recipes]))\n",
    "    # составляем матрицу\n",
    "    tc_matrix = pandas.DataFrame(data=np.zeros((model.num_topics, len(targets))), columns=targets)\n",
    "    for recipe, bow in zip(recipes, corpus):\n",
    "        recipe_topic = model.get_document_topics(bow)\n",
    "        for t, prob in recipe_topic:\n",
    "            tc_matrix[recipe[\"cuisine\"]][t] += prob\n",
    "    # нормируем матрицу\n",
    "    target_sums = pandas.DataFrame(data=np.zeros((1, len(targets))), columns=targets)\n",
    "    for recipe in recipes:\n",
    "        target_sums[recipe[\"cuisine\"]] += 1\n",
    "    return pandas.DataFrame(tc_matrix.values/target_sums.values, columns=tc_matrix.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_matrix(tc_matrix):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    seaborn.heatmap(tc_matrix, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAJ8CAYAAAAVo205AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1114c1c90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Визуализируйте матрицу\n",
    "plot_matrix(compute_topic_cuisine_matrix(lda, corpus, recipes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чем темнее квадрат в матрице, тем больше связь этой темы с данной кухней. Мы видим, что у нас есть темы, которые связаны с несколькими кухнями. Такие темы показывают набор ингредиентов, которые популярны в кухнях нескольких народов, то есть указывают на схожесть кухонь этих народов. Некоторые темы распределены по всем кухням равномерно, они показывают наборы продуктов, которые часто используются в кулинарии всех стран. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Жаль, что в датасете нет названий рецептов, иначе темы было бы проще интерпретировать..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Заключение\n",
    "В этом задании вы построили несколько моделей LDA, посмотрели, на что влияют гиперпараметры модели и как можно использовать построенную модель. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
